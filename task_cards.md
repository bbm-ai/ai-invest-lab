# ğŸ“‹ AI æŠ•è³‡åœ˜éšŠ - ä»»å‹™å¡ç³»çµ±

## ä»»å‹™å¡ä½¿ç”¨èªªæ˜

### ä»»å‹™å¡æ ¼å¼èªªæ˜
æ¯å¼µä»»å‹™å¡åŒ…å«ï¼š
- **ä»»å‹™ ID**ï¼šå”¯ä¸€æ¨™è­˜ç¬¦ï¼ˆæ ¼å¼ï¼šTASK-XXXï¼‰
- **éšæ®µæ¨™è¨˜**ï¼šæ‰€å±¬é–‹ç™¼éšæ®µ
- **å„ªå…ˆç´š**ï¼šP0ï¼ˆæœ€é«˜ï¼‰åˆ° P3ï¼ˆæœ€ä½ï¼‰
- **é ä¼°æ™‚é–“**ï¼šå®Œæˆæ‰€éœ€æ™‚é–“
- **å‰ç½®ä»»å‹™**ï¼šå¿…é ˆå…ˆå®Œæˆçš„ä»»å‹™
- **é©—æ”¶æ¨™æº–**ï¼šæ˜ç¢ºçš„å®Œæˆæ¨™æº–
- **è¼¸å‡ºç”¢ç‰©**ï¼šå…·é«”çš„äº¤ä»˜ç‰©
- **æª¢æŸ¥æ¸…å–®**ï¼šåŸ·è¡Œæ­¥é©Ÿæ¸…å–®

### ç‹€æ…‹æ¨™è¨˜
- ğŸ”µ TODOï¼šå¾…é–‹å§‹
- ğŸŸ¡ IN_PROGRESSï¼šé€²è¡Œä¸­
- ğŸŸ¢ DONEï¼šå·²å®Œæˆ
- ğŸ”´ BLOCKEDï¼šè¢«é˜»å¡
- âšª SKIPï¼šè·³é

---

# Phase 0: æº–å‚™éšæ®µ

## TASK-001: GitHub Repository å»ºç«‹
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 30åˆ†é˜  
**å‰ç½®ä»»å‹™ï¼š** ç„¡  

### ç›®æ¨™
å»ºç«‹å°ˆæ¡ˆçš„ GitHub Repositoryï¼Œè¨­ç½®åŸºç¤çµæ§‹

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. ç™»å…¥ GitHubï¼ˆæ‰‹æ©Ÿæˆ–é›»è…¦ï¼‰
- [ ] 2. é»æ“Š "New repository"
- [ ] 3. å¡«å¯«è³‡è¨Šï¼š
  - Repository name: ai-investment-team
  - Description: AI-powered investment analysis system
  - Public or Private: é¸æ“‡ Privateï¼ˆæ¨è–¦ï¼‰
  - Initialize with README: âœ“
  - Add .gitignore: Python
  - Choose license: MIT
- [ ] 4. é»æ“Š "Create repository"
- [ ] 5. å‰µå»ºåŸºç¤ç›®éŒ„çµæ§‹ï¼ˆå¯ç”¨ GitHub ç¶²é ç‰ˆï¼‰
  - å‰µå»º agents/ ç›®éŒ„
  - å‰µå»º data/ ç›®éŒ„
  - å‰µå»º docs/ ç›®éŒ„
  - å‰µå»º scripts/ ç›®éŒ„
  - å‰µå»º tests/ ç›®éŒ„
- [ ] 6. ä¸Šå‚³ .gitignore æ–‡ä»¶
- [ ] 7. ä¸Šå‚³ README.md åŸºç¤å…§å®¹
```

### é©—æ”¶æ¨™æº–
- [x] Repository å¯æ­£å¸¸è¨ªå•
- [x] åŸºç¤ç›®éŒ„çµæ§‹å®Œæ•´
- [x] .gitignore å·²é…ç½®
- [x] README æœ‰åŸºæœ¬èªªæ˜

### è¼¸å‡ºç”¢ç‰©
- `https://github.com/YOUR_USERNAME/ai-investment-team`
- åˆå§‹ç›®éŒ„çµæ§‹
- README.md

### å¾ŒçºŒä»»å‹™
â†’ TASK-002ï¼ˆAPI Keys ç”³è«‹ï¼‰

---

## TASK-002: å…è²» API Keys ç”³è«‹
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 1å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-001  

### ç›®æ¨™
ç”³è«‹æ‰€æœ‰éœ€è¦çš„å…è²» API Keys

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. Groq API Key
  - è¨ªå•ï¼šhttps://console.groq.com
  - è¨»å†Šå¸³è™Ÿï¼ˆGoogle å¸³è™Ÿå¿«é€Ÿè¨»å†Šï¼‰
  - å‰µå»º API Key
  - ä¿å­˜åˆ°å®‰å…¨ä½ç½®
  - æ¸¬è©¦ï¼šcurl 'https://api.groq.com/openai/v1/models' -H 'Authorization: Bearer YOUR_KEY'

- [ ] 2. Google AI Studio (Gemini)
  - è¨ªå•ï¼šhttps://aistudio.google.com/app/apikey
  - ä½¿ç”¨ Google å¸³è™Ÿç™»å…¥
  - é»æ“Š "Get API Key"
  - å‰µå»ºæ–° API Key
  - ä¿å­˜å¯†é‘°
  - æ¸¬è©¦é€£æ¥

- [ ] 3. Claude APIï¼ˆå¯é¸ï¼‰
  - è¨ªå•ï¼šhttps://console.anthropic.com
  - è¨»å†Šå¸³è™Ÿ
  - ç²å–å…è²» $5 é¡åº¦
  - å‰µå»º API Key
  - ä¿å­˜å¯†é‘°

- [ ] 4. GitHub Personal Access Token
  - Settings â†’ Developer settings â†’ Personal access tokens
  - Generate new token (classic)
  - å‹¾é¸æ¬Šé™ï¼šrepo, workflow
  - ç”Ÿæˆä¸¦ä¿å­˜ token

- [ ] 5. å‰µå»º .env.example æ–‡ä»¶
  - ä¸Šå‚³åˆ° GitHub
  - åˆ—å‡ºæ‰€æœ‰éœ€è¦çš„ç’°å¢ƒè®Šæ•¸
  
- [ ] 6. æœ¬åœ°å‰µå»º .env æ–‡ä»¶
  - å¡«å…¥æ‰€æœ‰ API keys
  - ç¢ºä¿ .gitignore åŒ…å« .env
```

### é©—æ”¶æ¨™æº–
- [x] Groq API æ¸¬è©¦æˆåŠŸ
- [x] Gemini API æ¸¬è©¦æˆåŠŸ
- [x] GitHub Token æœ‰æ•ˆ
- [x] .env.example å·²ä¸Šå‚³
- [x] æ‰€æœ‰ keys å®‰å…¨ä¿å­˜

### è¼¸å‡ºç”¢ç‰©
```bash
# .env.example
GROQ_API_KEY=your_groq_key_here
GEMINI_API_KEY=your_gemini_key_here
CLAUDE_API_KEY=your_claude_key_here
GITHUB_TOKEN=your_github_token_here
```

### æ¸¬è©¦å‘½ä»¤
```bash
# æ¸¬è©¦ Groq
curl -X POST "https://api.groq.com/openai/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"llama-3.1-8b-instant","messages":[{"role":"user","content":"test"}]}'

# æ¸¬è©¦ Geminiï¼ˆä½¿ç”¨ Pythonï¼‰
python3 -c "import google.generativeai as genai; genai.configure(api_key='YOUR_KEY'); print('OK')"
```

### å¾ŒçºŒä»»å‹™
â†’ TASK-003ï¼ˆGoogle Cloud VM å‰µå»ºï¼‰

---

## TASK-003: Google Cloud Free VM å‰µå»º
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 45åˆ†é˜  
**å‰ç½®ä»»å‹™ï¼š** TASK-002  

### ç›®æ¨™
å‰µå»º Google Cloud å…è²» VM å¯¦ä¾‹

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. è¨ªå• Google Cloud Console
  - https://console.cloud.google.com
  - ç™»å…¥ Google å¸³è™Ÿ
  
- [ ] 2. å‰µå»ºæˆ–é¸æ“‡å°ˆæ¡ˆ
  - å°ˆæ¡ˆåç¨±ï¼šai-investment-team
  - è¨˜éŒ„ Project ID
  
- [ ] 3. å•Ÿç”¨ Compute Engine API
  - æœç´¢ "Compute Engine"
  - é»æ“Š "Enable API"
  
- [ ] 4. å‰µå»º VM å¯¦ä¾‹
  - Compute Engine â†’ VM instances â†’ Create Instance
  - Name: ai-agent-vm
  - Region: us-central1 (æ„›è·è¯) âš ï¸ å¿…é ˆé¸å…è²»åœ°å€
  - Zone: us-central1-a
  - Machine configuration:
    * Series: E2
    * Machine type: e2-micro (0.25-2 vCPU, 1 GB memory)
  - Boot disk:
    * Operating system: Ubuntu
    * Version: Ubuntu 22.04 LTS
    * Boot disk type: Standard persistent disk
    * Size: 30 GB (å…è²»é¡åº¦)
  - Firewall: ä¸å‹¾é¸ HTTP/HTTPS
  - é»æ“Š "Create"
  
- [ ] 5. ç­‰å¾… VM å•Ÿå‹•ï¼ˆç´„1-2åˆ†é˜ï¼‰

- [ ] 6. æ¸¬è©¦ SSH é€£æ¥
  - é»æ“Š VM åç¨±
  - é»æ“Š "SSH" æŒ‰éˆ•
  - æˆ–ä½¿ç”¨ Cloud Shell: gcloud compute ssh ai-agent-vm --zone=us-central1-a
  
- [ ] 7. è¨­ç½®é˜²ç«ç‰†è¦å‰‡ï¼ˆåŸºæœ¬å®‰å…¨ï¼‰
  - VPC network â†’ Firewall
  - ç¢ºä¿åªé–‹æ”¾ SSH (22)
```

### é©—æ”¶æ¨™æº–
- [x] VM æˆåŠŸå‰µå»º
- [x] Region ç‚º us-central1ï¼ˆå…è²»ï¼‰
- [x] æ©Ÿå™¨é¡å‹ç‚º e2-micro
- [x] å¯ä»¥ SSH é€£æ¥
- [x] ç£ç¢Ÿå¤§å° = 30GB
- [x] æˆæœ¬é ä¼° = $0/æœˆ

### é‡è¦æª¢æŸ¥
```bash
# é€£æ¥å¾ŒåŸ·è¡Œï¼Œç¢ºèªé…ç½®
cat /etc/os-release  # ç¢ºèª Ubuntu 22.04
free -h              # ç¢ºèªè¨˜æ†¶é«” ~1GB
df -h                # ç¢ºèªç£ç¢Ÿ ~30GB
```

### âš ï¸ é¿å…æ”¶è²»é™·é˜±
```markdown
ç¢ºä¿ä»¥ä¸‹é…ç½®ï¼š
- âœ… Machine type: e2-micro
- âœ… Region: us-central1/us-west1/us-east1
- âŒ ä¸è¦æ·»åŠ éœæ…‹å¤–éƒ¨ IPï¼ˆæœƒæ”¶è²»ï¼‰
- âŒ ä¸è¦ä½¿ç”¨ SSDï¼ˆæœƒæ”¶è²»ï¼‰
- âŒ ä¸è¦æ·»åŠ  GPUï¼ˆæœƒæ”¶è²»ï¼‰
- âŒ ä¸è¦å‰µå»ºå¿«ç…§ï¼ˆè¶…é5GBæœƒæ”¶è²»ï¼‰
```

### è¼¸å‡ºç”¢ç‰©
- VM å¤–éƒ¨ IPï¼šè¨˜éŒ„åˆ°æ–‡æª”
- SSH é€£æ¥å‘½ä»¤ï¼š`gcloud compute ssh ai-agent-vm --zone=us-central1-a`

### å¾ŒçºŒä»»å‹™
â†’ TASK-004ï¼ˆVM ç’°å¢ƒåˆå§‹åŒ–ï¼‰

---

## TASK-004: VM ç’°å¢ƒåˆå§‹åŒ–
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 30åˆ†é˜  
**å‰ç½®ä»»å‹™ï¼š** TASK-003  

### ç›®æ¨™
åœ¨ VM ä¸Šå®‰è£å¿…è¦çš„è»Ÿä»¶å’Œé…ç½®ç’°å¢ƒ

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. SSH é€£æ¥åˆ° VM
  gcloud compute ssh ai-agent-vm --zone=us-central1-a

- [ ] 2. æ›´æ–°ç³»çµ±
  sudo apt update
  sudo apt upgrade -y

- [ ] 3. å®‰è£åŸºç¤å·¥å…·
  sudo apt install -y python3-pip git sqlite3 vim curl wget

- [ ] 4. é©—è­‰ Python ç‰ˆæœ¬
  python3 --version  # æ‡‰è©²æ˜¯ 3.10+

- [ ] 5. é…ç½® Git
  git config --global user.name "AI Investment Agent"
  git config --global user.email "agent@yourdomain.com"

- [ ] 6. ç”Ÿæˆ SSH Keyï¼ˆç”¨æ–¼ GitHubï¼‰
  ssh-keygen -t ed25519 -C "ai-agent@vm"
  cat ~/.ssh/id_ed25519.pub
  # è¤‡è£½å…¬é‘°ï¼Œæ·»åŠ åˆ° GitHub Settings â†’ SSH Keys

- [ ] 7. Clone Repository
  cd ~
  git clone git@github.com:YOUR_USERNAME/ai-investment-team.git
  cd ai-investment-team

- [ ] 8. å‰µå»ºè™›æ“¬ç’°å¢ƒ
  python3 -m venv venv
  source venv/bin/activate

- [ ] 9. å‰µå»ºå¿…è¦ç›®éŒ„
  mkdir -p data logs backups reports

- [ ] 10. è¨­ç½®ç’°å¢ƒè®Šæ•¸
  cp .env.example .env
  nano .env  # å¡«å…¥ API keys
  chmod 600 .env  # ä¿è­·æ–‡ä»¶æ¬Šé™
```

### é©—æ”¶æ¨™æº–
- [x] Python 3.10+ å·²å®‰è£
- [x] Git é…ç½®å®Œæˆ
- [x] Repository å·² clone
- [x] è™›æ“¬ç’°å¢ƒå·²å‰µå»º
- [x] ç›®éŒ„çµæ§‹å®Œæ•´
- [x] .env æ–‡ä»¶å·²é…ç½®

### æ¸¬è©¦å‘½ä»¤
```bash
# æ¸¬è©¦ Python
python3 -c "import sys; print(sys.version)"

# æ¸¬è©¦ Git
git --version

# æ¸¬è©¦ SQLite
sqlite3 --version

# ç¢ºèªç›®éŒ„
ls -la ~/ai-investment-team
```

### è¼¸å‡ºç”¢ç‰©
- é…ç½®å®Œæˆçš„ VM ç’°å¢ƒ
- Clone çš„ä»£ç¢¼åº«
- .env é…ç½®æ–‡ä»¶

### å¾ŒçºŒä»»å‹™
â†’ TASK-005ï¼ˆå°ˆæ¡ˆæ–‡æª”å»ºç«‹ï¼‰

---

## TASK-005: å°ˆæ¡ˆæ–‡æª”å»ºç«‹
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P1  
**é ä¼°æ™‚é–“ï¼š** 1å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-001  

### ç›®æ¨™
å»ºç«‹å®Œæ•´çš„å°ˆæ¡ˆæ–‡æª”çµæ§‹

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º README.md
  - å°ˆæ¡ˆç°¡ä»‹
  - åŠŸèƒ½ç‰¹é»
  - å¿«é€Ÿé–‹å§‹
  - æŠ€è¡“æ£§
  - æˆæ¬Šä¿¡æ¯

- [ ] 2. å‰µå»º docs/ARCHITECTURE.md
  - ç³»çµ±æ¶æ§‹åœ–
  - æ¨¡å¡Šèªªæ˜
  - æ•¸æ“šæµç¨‹
  - API è¨­è¨ˆ

- [ ] 3. å‰µå»º docs/DEPLOYMENT.md
  - éƒ¨ç½²æ­¥é©Ÿ
  - ç’°å¢ƒè¦æ±‚
  - é…ç½®èªªæ˜
  - æ•…éšœæ’é™¤

- [ ] 4. å‰µå»º docs/API.md
  - API ç«¯é»åˆ—è¡¨
  - è«‹æ±‚/éŸ¿æ‡‰æ ¼å¼
  - éŒ¯èª¤ç¢¼èªªæ˜
  - ä½¿ç”¨ç¤ºä¾‹

- [ ] 5. å‰µå»º docs/TASKS.md
  - è¤‡è£½ä»»å‹™å¡å…§å®¹
  - ä»»å‹™è¿½è¹¤è¡¨
  - é€²åº¦å„€è¡¨æ¿

- [ ] 6. å‰µå»º CHANGELOG.md
  - ç‰ˆæœ¬è¨˜éŒ„æ ¼å¼
  - åˆå§‹ç‰ˆæœ¬èªªæ˜

- [ ] 7. æ›´æ–° .gitignore
  - æ·»åŠ æ‰€æœ‰æ•æ„Ÿæ–‡ä»¶
  - æ·»åŠ è‡¨æ™‚æ–‡ä»¶æ¨¡å¼
```

### é©—æ”¶æ¨™æº–
- [x] æ‰€æœ‰æ–‡æª”æ–‡ä»¶å·²å‰µå»º
- [x] å…§å®¹çµæ§‹å®Œæ•´
- [x] Markdown æ ¼å¼æ­£ç¢º
- [x] å·²æäº¤åˆ° GitHub

### è¼¸å‡ºç”¢ç‰©
```
docs/
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ DEPLOYMENT.md
â”œâ”€â”€ API.md
â”œâ”€â”€ TASKS.md
â””â”€â”€ TROUBLESHOOTING.md
README.md
CHANGELOG.md
.gitignore
```

### å¾ŒçºŒä»»å‹™
â†’ TASK-006ï¼ˆrequirements.txt å‰µå»ºï¼‰

---

## TASK-006: Python ä¾è³´é…ç½®
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 0  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 30åˆ†é˜  
**å‰ç½®ä»»å‹™ï¼š** TASK-004  

### ç›®æ¨™
å‰µå»º requirements.txt ä¸¦å®‰è£ä¾è³´

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º requirements.txt
- [ ] 2. åœ¨ VM ä¸Šå®‰è£ä¾è³´
  source venv/bin/activate
  pip install -r requirements.txt
- [ ] 3. é©—è­‰å®‰è£
  pip list
- [ ] 4. æ¸¬è©¦é—œéµåº«
  python3 -c "import anthropic; print('Anthropic OK')"
  python3 -c "import google.generativeai; print('Gemini OK')"
  python3 -c "import groq; print('Groq OK')"
  python3 -c "import yfinance; print('yfinance OK')"
- [ ] 5. æäº¤åˆ° GitHub
  git add requirements.txt
  git commit -m "Add Python dependencies"
  git push
```

### requirements.txt å…§å®¹
```txt
# AI APIs
anthropic>=0.18.0
google-generativeai>=0.3.0
groq>=0.4.0

# æ•¸æ“šè™•ç†
pandas>=2.0.0
numpy>=1.24.0
yfinance>=0.2.28

# æ•¸æ“šåº«
sqlalchemy>=2.0.0

# æŠ€è¡“åˆ†æ
ta-lib>=0.4.0  # éœ€è¦å…ˆå®‰è£ C ä¾è³´
pandas-ta>=0.3.14b0

# å·¥å…·
python-dotenv>=1.0.0
pyyaml>=6.0
requests>=2.31.0
schedule>=1.2.0

# æ¸¬è©¦
pytest>=7.4.0
pytest-cov>=4.1.0

# æ—¥èªŒ
loguru>=0.7.0

# Webï¼ˆå¯é¸ï¼‰
streamlit>=1.28.0
plotly>=5.17.0
```

### å®‰è£ TA-Libï¼ˆæŠ€è¡“åˆ†æåº«ï¼‰
```bash
# Ubuntu ä¸Šå®‰è£ TA-Lib C ä¾è³´
sudo apt-get install -y build-essential wget
wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz
tar -xzf ta-lib-0.4.0-src.tar.gz
cd ta-lib/
./configure --prefix=/usr
make
sudo make install
cd ..
rm -rf ta-lib ta-lib-0.4.0-src.tar.gz

# ç„¶å¾Œå®‰è£ Python åŒ…
pip install ta-lib
```

### é©—æ”¶æ¨™æº–
- [x] requirements.txt å·²å‰µå»º
- [x] æ‰€æœ‰ä¾è³´å®‰è£æˆåŠŸ
- [x] æ¸¬è©¦å‘½ä»¤éƒ½é€šé
- [x] æ–‡ä»¶å·²æäº¤åˆ° GitHub

### è¼¸å‡ºç”¢ç‰©
- requirements.txt
- å®‰è£å¥½ä¾è³´çš„è™›æ“¬ç’°å¢ƒ

### å¾ŒçºŒä»»å‹™
â†’ TASK-007ï¼ˆæ•¸æ“šåº«çµæ§‹è¨­è¨ˆï¼‰

---

# Phase 1: MVP åŸºç¤æ¶æ§‹

## TASK-007: æ•¸æ“šåº«çµæ§‹è¨­è¨ˆèˆ‡åˆå§‹åŒ–
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 1  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 2å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-006  

### ç›®æ¨™
è¨­è¨ˆä¸¦å‰µå»º SQLite æ•¸æ“šåº«çµæ§‹

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º database/schema.sql
  - è¨­è¨ˆæ‰€æœ‰è¡¨çµæ§‹
  - æ·»åŠ ç´¢å¼•
  - æ·»åŠ è¨»é‡‹

- [ ] 2. å‰µå»º database/models.py
  - å®šç¾© SQLAlchemy æ¨¡å‹
  - æ·»åŠ é—œä¿‚
  - æ·»åŠ é©—è­‰

- [ ] 3. å‰µå»º scripts/init_database.py
  - è®€å– schema.sql
  - å‰µå»ºæ•¸æ“šåº«
  - åˆå§‹åŒ–è¡¨
  - æ’å…¥æ¸¬è©¦æ•¸æ“š

- [ ] 4. åŸ·è¡Œåˆå§‹åŒ–
  python3 scripts/init_database.py

- [ ] 5. é©—è­‰æ•¸æ“šåº«
  sqlite3 data/investment.db
  .tables
  .schema prices

- [ ] 6. å‰µå»ºæ•¸æ“šåº«æ“ä½œå°è£
  database/operations.py

- [ ] 7. ç·¨å¯«å–®å…ƒæ¸¬è©¦
  tests/test_database.py
```

### database/schema.sql
```sql
-- åƒ¹æ ¼æ•¸æ“šè¡¨
CREATE TABLE IF NOT EXISTS prices (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    date DATE NOT NULL,
    open REAL NOT NULL,
    high REAL NOT NULL,
    low REAL NOT NULL,
    close REAL NOT NULL,
    volume INTEGER NOT NULL,
    adj_close REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol, date)
);

CREATE INDEX idx_prices_symbol_date ON prices(symbol, date DESC);
CREATE INDEX idx_prices_date ON prices(date DESC);

-- æŠ€è¡“æŒ‡æ¨™è¡¨
CREATE TABLE IF NOT EXISTS indicators (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    date DATE NOT NULL,
    sma_20 REAL,
    sma_50 REAL,
    sma_200 REAL,
    rsi_14 REAL,
    macd REAL,
    macd_signal REAL,
    macd_hist REAL,
    bb_upper REAL,
    bb_middle REAL,
    bb_lower REAL,
    volume_sma REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol, date)
);

CREATE INDEX idx_indicators_symbol_date ON indicators(symbol, date DESC);

-- åˆ†æçµæœè¡¨
CREATE TABLE IF NOT EXISTS analysis (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    date DATE NOT NULL,
    signal TEXT CHECK(signal IN ('buy', 'sell', 'hold')),
    confidence REAL CHECK(confidence BETWEEN 0 AND 1),
    trend TEXT CHECK(trend IN ('bullish', 'bearish', 'neutral')),
    strength REAL CHECK(strength BETWEEN 0 AND 1),
    support_levels TEXT,  -- JSON array
    resistance_levels TEXT,  -- JSON array
    reasoning TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol, date)
);

CREATE INDEX idx_analysis_symbol_date ON analysis(symbol, date DESC);
CREATE INDEX idx_analysis_signal ON analysis(signal);

-- ç­–ç•¥æ±ºç­–è¡¨
CREATE TABLE IF NOT EXISTS strategies (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    date DATE NOT NULL,
    symbol TEXT NOT NULL,
    action TEXT CHECK(action IN ('buy', 'sell', 'hold')),
    position_size REAL CHECK(position_size BETWEEN 0 AND 1),
    entry_price REAL,
    stop_loss REAL,
    take_profit REAL,
    risk_reward_ratio REAL,
    reasoning TEXT,
    status TEXT CHECK(status IN ('pending', 'executed', 'cancelled')) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_strategies_date ON strategies(date DESC);
CREATE INDEX idx_strategies_status ON strategies(status);

-- æŠ•è³‡çµ„åˆè¡¨
CREATE TABLE IF NOT EXISTS portfolio (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    quantity REAL NOT NULL DEFAULT 0,
    avg_cost REAL,
    current_price REAL,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol)
);

-- äº¤æ˜“è¨˜éŒ„è¡¨
CREATE TABLE IF NOT EXISTS trades (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    action TEXT CHECK(action IN ('buy', 'sell')),
    quantity REAL NOT NULL,
    price REAL NOT NULL,
    commission REAL DEFAULT 0,
    total_amount REAL NOT NULL,
    trade_date DATE NOT NULL,
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_trades_symbol ON trades(symbol);
CREATE INDEX idx_trades_date ON trades(trade_date DESC);

-- Agent åŸ·è¡Œæ—¥èªŒè¡¨
CREATE TABLE IF NOT EXISTS execution_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_name TEXT NOT NULL,
    task_name TEXT,
    status TEXT CHECK(status IN ('success', 'failed', 'running', 'skipped')),
    message TEXT,
    execution_time REAL,  -- ç§’
    error_details TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_logs_agent_date ON execution_logs(agent_name, created_at DESC);
CREATE INDEX idx_logs_status ON execution_logs(status);

-- ç³»çµ±é…ç½®è¡¨
CREATE TABLE IF NOT EXISTS system_config (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    description TEXT,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ’å…¥é»˜èªé…ç½®
INSERT OR IGNORE INTO system_config (key, value, description) VALUES
('last_sync_time', '2024-01-01 00:00:00', 'æœ€å¾ŒåŒæ­¥æ™‚é–“'),
('active_symbols', '["SPY"]', 'ç•¶å‰æ´»èºè¿½è¹¤çš„æ¨™çš„'),
('risk_level', 'moderate', 'é¢¨éšªç­‰ç´š'),
('max_position_size', '0.3', 'å–®ä¸€æ¨™çš„æœ€å¤§å€‰ä½æ¯”ä¾‹');
```

### scripts/init_database.py
```python
#!/usr/bin/env python3
"""
æ•¸æ“šåº«åˆå§‹åŒ–è…³æœ¬
"""
import sqlite3
import os
from pathlib import Path

def init_database():
    """åˆå§‹åŒ–æ•¸æ“šåº«"""
    
    # ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    db_path = data_dir / "investment.db"
    schema_path = Path("database/schema.sql")
    
    # è®€å– schema
    if not schema_path.exists():
        raise FileNotFoundError(f"Schema file not found: {schema_path}")
    
    with open(schema_path, 'r') as f:
        schema_sql = f.read()
    
    # å‰µå»ºæ•¸æ“šåº«
    print(f"Creating database at: {db_path}")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # åŸ·è¡Œ schema
    cursor.executescript(schema_sql)
    conn.commit()
    
    # é©—è­‰è¡¨å‰µå»º
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table'
        ORDER BY name
    """)
    
    tables = cursor.fetchall()
    print(f"\nCreated {len(tables)} tables:")
    for table in tables:
        print(f"  - {table[0]}")
    
    conn.close()
    print(f"\nâœ… Database initialized successfully!")
    print(f"Location: {db_path.absolute()}")

if __name__ == "__main__":
    init_database()
```

### é©—æ”¶æ¨™æº–
- [x] schema.sql å®Œæ•´ç„¡èª¤
- [x] æ•¸æ“šåº«æˆåŠŸå‰µå»º
- [x] æ‰€æœ‰è¡¨å’Œç´¢å¼•æ­£ç¢º
- [x] åˆå§‹åŒ–è…³æœ¬å¯é‡è¤‡åŸ·è¡Œ
- [x] æ¸¬è©¦ç”¨ä¾‹é€šé

### æ¸¬è©¦å‘½ä»¤
```bash
# åˆå§‹åŒ–æ•¸æ“šåº«
python3 scripts/init_database.py

# é©—è­‰
sqlite3 data/investment.db << EOF
.tables
SELECT COUNT(*) FROM system_config;
EOF

# é‹è¡Œæ¸¬è©¦
pytest tests/test_database.py -v
```

### è¼¸å‡ºç”¢ç‰©
- database/schema.sql
- database/models.py
- database/operations.py
- scripts/init_database.py
- data/investment.db
- tests/test_database.py

### å¾ŒçºŒä»»å‹™
â†’ TASK-008ï¼ˆæ•¸æ“šæ”¶é›† Agentï¼‰

---

## TASK-008: Data Collector Agent é–‹ç™¼
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 1  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 4å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-007  

### ç›®æ¨™
é–‹ç™¼æ•¸æ“šæ”¶é›† Agentï¼Œè‡ªå‹•ç²å–å¸‚å ´æ•¸æ“š

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º agents/data_collector.py
  - DataCollector é¡
  - å¾ yfinance ç²å–æ•¸æ“š
  - éŒ¯èª¤è™•ç†å’Œé‡è©¦
  - æ—¥èªŒè¨˜éŒ„

- [ ] 2. å¯¦ç¾æ ¸å¿ƒåŠŸèƒ½
  - collect_price_data()
  - store_to_database()
  - validate_data()
  - log_execution()

- [ ] 3. æ·»åŠ  Groq AI å¢å¼·
  - ç•°å¸¸æ•¸æ“šè­˜åˆ¥
  - æ•¸æ“šè³ªé‡è©•ä¼°
  - è‡ªå‹•ä¿®æ­£å»ºè­°

- [ ] 4. ç·¨å¯«é…ç½®æ–‡ä»¶
  config/collector_config.yaml

- [ ] 5. ç·¨å¯«å–®å…ƒæ¸¬è©¦
  tests/test_data_collector.py

- [ ] 6. æ¸¬è©¦é‹è¡Œ
  python3 agents/data_collector.py --symbol SPY

- [ ] 7. æ–‡æª”æ›´æ–°
  docs/API.md æ·»åŠ  Data Collector èªªæ˜
```

### agents/data_collector.py
```python
#!/usr/bin/env python3
"""
Data Collector Agent
è² è²¬æ”¶é›†å¸‚å ´æ•¸æ“š
"""
import yfinance as yf
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from loguru import logger
import os
from groq import Groq

class DataCollector:
    """æ•¸æ“šæ”¶é›† Agent"""
    
    def __init__(self, db_path: str = "data/investment.db"):
        self.db_path = db_path
        self.groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))
        logger.add("logs/data_collector.log", rotation="1 day")
        
    def collect_price_data(
        self, 
        symbol: str, 
        period: str = "1d"
    ) -> Optional[Dict]:
        """
        æ”¶é›†åƒ¹æ ¼æ•¸æ“š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            period: æ™‚é–“é€±æœŸ (1d, 5d, 1mo, ç­‰)
            
        Returns:
            æ•¸æ“šå­—å…¸æˆ– None
        """
        try:
            logger.info(f"Collecting data for {symbol}...")
            
            # ç²å–æ•¸æ“š
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period=period)
            
            if hist.empty:
                logger.warning(f"No data found for {symbol}")
                return None
            
            # ç²å–æœ€æ–°æ•¸æ“š
            latest = hist.iloc[-1]
            date = hist.index[-1].date()
            
            data = {
                'symbol': symbol,
                'date': str(date),
                'open': float(latest['Open']),
                'high': float(latest['High']),
                'low': float(latest['Low']),
                'close': float(latest['Close']),
                'volume': int(latest['Volume']),
                'adj_close': float(latest['Close'])  # yfinance å·²èª¿æ•´
            }
            
            # ä½¿ç”¨ Groq é©—è­‰æ•¸æ“šè³ªé‡
            is_valid = self.validate_data_with_ai(data)
            if not is_valid:
                logger.warning(f"Data quality check failed for {symbol}")
            
            logger.success(f"Collected data for {symbol}: ${data['close']:.2f}")
            return data
            
        except Exception as e:
            logger.error(f"Error collecting data for {symbol}: {e}")
            return None
    
    def validate_data_with_ai(self, data: Dict) -> bool:
        """ä½¿ç”¨ Groq AI é©—è­‰æ•¸æ“šè³ªé‡"""
        try:
            prompt = f"""
            æª¢æŸ¥ä»¥ä¸‹å¸‚å ´æ•¸æ“šæ˜¯å¦åˆç†ï¼š
            é–‹ç›¤: ${data['open']:.2f}
            æœ€é«˜: ${data['high']:.2f}
            æœ€ä½: ${data['low']:.2f}
            æ”¶ç›¤: ${data['close']:.2f}
            æˆäº¤é‡: {data['volume']:,}
            
            è«‹å›ç­”ï¼šæ•¸æ“šæ˜¯å¦åˆç†ï¼Ÿåªå›ç­” YES æˆ– NO
            """
            
            response = self.groq_client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10
            )
            
            answer = response.choices[0].message.content.strip().upper()
            return "YES" in answer
            
        except Exception as e:
            logger.warning(f"AI validation failed: {e}")
            return True  # å¦‚æœ AI å¤±æ•—ï¼Œä»æ¥å—æ•¸æ“š
    
    def store_to_database(self, data: Dict) -> bool:
        """å­˜å„²æ•¸æ“šåˆ°æ•¸æ“šåº«"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO prices 
                (symbol, date, open, high, low, close, volume, adj_close)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                data['symbol'],
                data['date'],
                data['open'],
                data['high'],
                data['low'],
                data['close'],
                data['volume'],
                data['adj_close']
            ))
            
            conn.commit()
            conn.close()
            
            logger.success(f"Stored data for {data['symbol']} on {data['date']}")
            return True
            
        except Exception as e:
            logger.error(f"Database error: {e}")
            return False
    
    def log_execution(self, status: str, message: str, exec_time: float):
        """è¨˜éŒ„åŸ·è¡Œæ—¥èªŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO execution_logs 
                (agent_name, task_name, status, message, execution_time)
                VALUES (?, ?, ?, ?, ?)
            """, ('DataCollector', 'collect_data', status, message, exec_time))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Failed to log execution: {e}")
    
    def run(self, symbols: List[str]):
        """é‹è¡Œæ•¸æ“šæ”¶é›†"""
        start_time = datetime.now()
        
        for symbol in symbols:
            data = self.collect_price_data(symbol)
            if data:
                self.store_to_database(data)
        
        exec_time = (datetime.now() - start_time).total_seconds()
        self.log_execution('success', f'Collected {len(symbols)} symbols', exec_time)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--symbol', type=str, default='SPY')
    args = parser.parse_args()
    
    collector = DataCollector()
    collector.run([args.symbol])
```

### é©—æ”¶æ¨™æº–
- [x] èƒ½æˆåŠŸç²å– SPY æ•¸æ“š
- [x] æ•¸æ“šæ­£ç¢ºå­˜å…¥æ•¸æ“šåº«
- [x] Groq AI é©—è­‰å·¥ä½œ
- [x] éŒ¯èª¤è™•ç†å®Œå–„
- [x] æ—¥èªŒè¨˜éŒ„å®Œæ•´
- [x] å–®å…ƒæ¸¬è©¦é€šé

### æ¸¬è©¦å‘½ä»¤
```bash
# æ¸¬è©¦å–®å€‹æ¨™çš„
python3 agents/data_collector.py --symbol SPY

# æª¢æŸ¥æ•¸æ“šåº«
sqlite3 data/investment.db "SELECT * FROM prices ORDER BY date DESC LIMIT 5"

# é‹è¡Œæ¸¬è©¦
pytest tests/test_data_collector.py -v
```

### è¼¸å‡ºç”¢ç‰©
- agents/data_collector.py
- tests/test_data_collector.py
- logs/data_collector.log

### å¾ŒçºŒä»»å‹™
â†’ TASK-009ï¼ˆæŠ€è¡“æŒ‡æ¨™è¨ˆç®—ï¼‰

---

## TASK-009: æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¨¡å¡Š
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 1  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 3å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-008  

### ç›®æ¨™
å¯¦ç¾å¸¸ç”¨æŠ€è¡“æŒ‡æ¨™çš„è¨ˆç®—

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º utils/indicators.py
- [ ] 2. å¯¦ç¾æŠ€è¡“æŒ‡æ¨™
  - SMA (ç°¡å–®ç§»å‹•å¹³å‡)
  - EMA (æŒ‡æ•¸ç§»å‹•å¹³å‡)
  - RSI (ç›¸å°å¼·å¼±æŒ‡æ¨™)
  - MACD (ç§»å‹•å¹³å‡æ”¶æ–‚æ•£åº¦)
  - Bollinger Bands (å¸ƒæ—å¸¶)
  - Volume Analysis
- [ ] 3. å‰µå»ºæŒ‡æ¨™è¨ˆç®— Agent
  agents/indicator_calculator.py
- [ ] 4. ç·¨å¯«æ¸¬è©¦
  tests/test_indicators.py
- [ ] 5. æ¸¬è©¦é‹è¡Œ
```

### utils/indicators.py
```python
#!/usr/bin/env python3
"""
æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å·¥å…·
"""
import pandas as pd
import numpy as np
from typing import Dict

class TechnicalIndicators:
    """æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate_sma(data: pd.Series, period: int) -> pd.Series:
        """ç°¡å–®ç§»å‹•å¹³å‡ç·š"""
        return data.rolling(window=period).mean()
    
    @staticmethod
    def calculate_ema(data: pd.Series, period: int) -> pd.Series:
        """æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š"""
        return data.ewm(span=period, adjust=False).mean()
    
    @staticmethod
    def calculate_rsi(data: pd.Series, period: int = 14) -> pd.Series:
        """ç›¸å°å¼·å¼±æŒ‡æ¨™"""
        delta = data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    @staticmethod
    def calculate_macd(
        data: pd.Series, 
        fast: int = 12, 
        slow: int = 26, 
        signal: int = 9
    ) -> Dict[str, pd.Series]:
        """MACD æŒ‡æ¨™"""
        ema_fast = data.ewm(span=fast).mean()
        ema_slow = data.ewm(span=slow).mean()
        
        macd = ema_fast - ema_slow
        signal_line = macd.ewm(span=signal).mean()
        histogram = macd - signal_line
        
        return {
            'macd': macd,
            'signal': signal_line,
            'histogram': histogram
        }
    
    @staticmethod
    def calculate_bollinger_bands(
        data: pd.Series, 
        period: int = 20, 
        std: float = 2.0
    ) -> Dict[str, pd.Series]:
        """å¸ƒæ—å¸¶"""
        middle = data.rolling(window=period).mean()
        std_dev = data.rolling(window=period).std()
        
        upper = middle + (std_dev * std)
        lower = middle - (std_dev * std)
        
        return {
            'upper': upper,
            'middle': middle,
            'lower': lower
        }
    
    @staticmethod
    def calculate_all_indicators(df: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—æ‰€æœ‰æŒ‡æ¨™"""
        close = df['close']
        
        # ç§»å‹•å¹³å‡
        df['sma_20'] = TechnicalIndicators.calculate_sma(close, 20)
        df['sma_50'] = TechnicalIndicators.calculate_sma(close, 50)
        df['sma_200'] = TechnicalIndicators.calculate_sma(close, 200)
        
        # RSI
        df['rsi_14'] = TechnicalIndicators.calculate_rsi(close, 14)
        
        # MACD
        macd = TechnicalIndicators.calculate_macd(close)
        df['macd'] = macd['macd']
        df['macd_signal'] = macd['signal']
        df['macd_hist'] = macd['histogram']
        
        # å¸ƒæ—å¸¶
        bb = TechnicalIndicators.calculate_bollinger_bands(close)
        df['bb_upper'] = bb['upper']
        df['bb_middle'] = bb['middle']
        df['bb_lower'] = bb['lower']
        
        # æˆäº¤é‡å‡ç·š
        df['volume_sma'] = TechnicalIndicators.calculate_sma(df['volume'], 20)
        
        return df
```

### é©—æ”¶æ¨™æº–
- [x] æ‰€æœ‰æŒ‡æ¨™è¨ˆç®—æ­£ç¢º
- [x] è™•ç† NaN å€¼
- [x] æ€§èƒ½å¯æ¥å—
- [x] æ¸¬è©¦ç”¨ä¾‹é€šé

### å¾ŒçºŒä»»å‹™
â†’ TASK-010ï¼ˆAnalyst Agent é–‹ç™¼ï¼‰

---

## TASK-010: Analyst Agent é–‹ç™¼
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 1  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 4å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-009  

### ç›®æ¨™
é–‹ç™¼åˆ†æå¸« Agentï¼Œä½¿ç”¨ Gemini AI é€²è¡ŒæŠ€è¡“åˆ†æ

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º agents/analyst.py
- [ ] 2. æ•´åˆ Gemini API
- [ ] 3. å¯¦ç¾åˆ†æé‚è¼¯
  - è®€å–åƒ¹æ ¼å’ŒæŒ‡æ¨™æ•¸æ“š
  - ç”Ÿæˆåˆ†æ prompt
  - èª¿ç”¨ Gemini
  - è§£æçµæœ
  - å­˜å…¥æ•¸æ“šåº«
- [ ] 4. ç·¨å¯«æ¸¬è©¦
- [ ] 5. æ¸¬è©¦é‹è¡Œ
```

### agents/analyst.py æ ¸å¿ƒä»£ç¢¼
```python
#!/usr/bin/env python3
"""
Analyst Agent
ä½¿ç”¨ Gemini AI é€²è¡ŒæŠ€è¡“åˆ†æ
"""
import google.generativeai as genai
import sqlite3
import pandas as pd
from datetime import datetime
import json
import os
from loguru import logger

class AnalystAgent:
    """æŠ€è¡“åˆ†æå¸« Agent"""
    
    def __init__(self, db_path: str = "data/investment.db"):
        self.db_path = db_path
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        logger.add("logs/analyst.log", rotation="1 day")
    
    def get_latest_data(self, symbol: str, days: int = 30) -> pd.DataFrame:
        """ç²å–æœ€è¿‘çš„æ•¸æ“š"""
        conn = sqlite3.connect(self.db_path)
        
        query = """
        SELECT p.*, i.*
        FROM prices p
        LEFT JOIN indicators i ON p.symbol = i.symbol AND p.date = i.date
        WHERE p.symbol = ?
        ORDER BY p.date DESC
        LIMIT ?
        """
        
        df = pd.read_sql_query(query, conn, params=(symbol, days))
        conn.close()
        
        return df
    
    def analyze(self, symbol: str) -> dict:
        """åŸ·è¡ŒæŠ€è¡“åˆ†æ"""
        try:
            logger.info(f"Analyzing {symbol}...")
            
            # ç²å–æ•¸æ“š
            df = self.get_latest_data(symbol)
            if df.empty:
                logger.warning(f"No data for {symbol}")
                return None
            
            latest = df.iloc[0]
            
            # æ§‹å»º prompt
            prompt = self.build_analysis_prompt(symbol, df, latest)
            
            # èª¿ç”¨ Gemini
            response = self.model.generate_content(prompt)
            result_text = response.text
            
            # è§£æçµæœï¼ˆå‡è¨­ AI è¿”å› JSONï¼‰
            result = self.parse_analysis_result(result_text)
            
            # å­˜å…¥æ•¸æ“šåº«
            self.store_analysis(symbol, result)
            
            logger.success(f"Analysis complete for {symbol}")
            return result
            
        except Exception as e:
            logger.error(f"Analysis failed for {symbol}: {e}")
            return None
    
    def build_analysis_prompt(self, symbol: str, df: pd.DataFrame, latest: pd.Series) -> str:
        """æ§‹å»ºåˆ†æ prompt"""
        prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“åˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹è‚¡ç¥¨æ•¸æ“šï¼š

æ¨™çš„ï¼š{symbol}
ç•¶å‰åƒ¹æ ¼ï¼š${latest['close']:.2f}
æ—¥æœŸï¼š{latest['date']}

æŠ€è¡“æŒ‡æ¨™ï¼š
- SMA20: ${latest.get('sma_20', 0):.2f}
- SMA50: ${latest.get('sma_50', 0):.2f}
- RSI(14): {latest.get('rsi_14', 0):.2f}
- MACD: {latest.get('macd', 0):.4f}
- å¸ƒæ—å¸¶: ä¸Šè»Œ ${latest.get('bb_upper', 0):.2f}, ä¸‹è»Œ ${latest.get('bb_lower', 0):.2f}

è¿‘æœŸè¶¨å‹¢ï¼š
- 5æ—¥æ¼²è·Œ: {((df.iloc[0]['close'] / df.iloc[4]['close'] - 1) * 100):.2f}%
- 20æ—¥æ¼²è·Œ: {((df.iloc[0]['close'] / df.iloc[19]['close'] - 1) * 100):.2f}%

è«‹æä¾›ï¼š
1. è¶¨å‹¢åˆ¤æ–·ï¼ˆä¸Šå‡/ä¸‹é™/æ©«ç›¤ï¼‰
2. è¶¨å‹¢å¼·åº¦ï¼ˆ0-1ï¼‰
3. äº¤æ˜“å»ºè­°ï¼ˆbuy/sell/holdï¼‰
4. ä¿¡å¿ƒæ°´å¹³ï¼ˆ0-1ï¼‰
5. æ”¯æ’ä½ï¼ˆåˆ—è¡¨ï¼‰
6. é˜»åŠ›ä½ï¼ˆåˆ—è¡¨ï¼‰
7. è©³ç´°æ¨ç†

è«‹ä»¥ JSON æ ¼å¼å›è¦†ï¼š
{{
  "trend": "ä¸Šå‡",
  "strength": 0.75,
  "signal": "buy",
  "confidence": 0.8,
  "support_levels": [480, 475],
  "resistance_levels": [490, 495],
  "reasoning": "è©³ç´°åˆ†æ..."
}}
"""
        return prompt
    
    def parse_analysis_result(self, text: str) -> dict:
        """è§£æ AI è¿”å›çš„çµæœ"""
        try:
            # æå– JSON
            if "```json" in text:
                json_str = text.split("```json")[1].split("```")[0]
            else:
                json_str = text
            
            result = json.loads(json_str.strip())
            return result
        except:
            # å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å›é»˜èªçµæœ
            return {
                "trend": "neutral",
                "strength": 0.5,
                "signal": "hold",
                "confidence": 0.5,
                "support_levels": [],
                "resistance_levels": [],
                "reasoning": text
            }
    
    def store_analysis(self, symbol: str, result: dict):
        """å­˜å„²åˆ†æçµæœ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO analysis
            (symbol, date, signal, confidence, trend, strength, 
             support_levels, resistance_levels, reasoning)
            VALUES (?, DATE('now'), ?, ?, ?, ?, ?, ?, ?)
        """, (
            symbol,
            result.get('signal', 'hold'),
            result.get('confidence', 0.5),
            result.get('trend', 'neutral'),
            result.get('strength', 0.5),
            json.dumps(result.get('support_levels', [])),
            json.dumps(result.get('resistance_levels', [])),
            result.get('reasoning', '')
        ))
        
        conn.commit()
        conn.close()

if __name__ == "__main__":
    analyst = AnalystAgent()
    result = analyst.analyze('SPY')
    print(json.dumps(result, indent=2))
```

### é©—æ”¶æ¨™æº–
- [x] Gemini API èª¿ç”¨æˆåŠŸ
- [x] åˆ†æçµæœåˆç†
- [x] JSON è§£ææ­£ç¢º
- [x] æ•¸æ“šæ­£ç¢ºå­˜å„²
- [x] æ—¥èªŒè¨˜éŒ„å®Œæ•´

### è¼¸å‡ºç”¢ç‰©
- agents/analyst.py
- tests/test_analyst.py
- logs/analyst.log

### å¾ŒçºŒä»»å‹™
â†’ TASK-011ï¼ˆMaster Agent é–‹ç™¼ï¼‰

---

ç”±æ–¼å…§å®¹å¾ˆé•·ï¼Œè®“æˆ‘ç¹¼çºŒå‰µå»ºå‰©é¤˜çš„é—œéµä»»å‹™å¡ã€‚æˆ‘æœƒé‡é»æ”¾åœ¨æœ€é‡è¦çš„ä»»å‹™ä¸Šã€‚

## TASK-011: Master Agent èª¿åº¦ç³»çµ±
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 1  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 6å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-010  

### ç›®æ¨™
é–‹ç™¼ Master Agentï¼Œå”èª¿æ‰€æœ‰å…¶ä»– Agents

### æ ¸å¿ƒåŠŸèƒ½
```python
class MasterAgent:
    """ä¸»æ§ Agent"""
    
    def __init__(self):
        self.config = self.load_config()
        self.state = self.load_state()
        self.agents = {
            'collector': DataCollector(),
            'analyst': AnalystAgent(),
            'strategist': StrategistAgent()
        }
    
    def run(self):
        """ä¸»å¾ªç’°"""
        while True:
            # 1. æª¢æŸ¥æ™‚é–“å’Œè¨ˆåŠƒ
            task = self.get_next_task()
            
            # 2. åŸ·è¡Œä»»å‹™
            if task:
                self.execute_task(task)
            
            # 3. ä¿å­˜ç‹€æ…‹
            self.save_state()
            
            # 4. ç­‰å¾…ä¸‹ä¸€é€±æœŸ
            time.sleep(60)
```

### é©—æ”¶æ¨™æº–
- [x] èƒ½èª¿åº¦æ‰€æœ‰ Agents
- [x] æ™‚é–“èª¿åº¦æº–ç¢º
- [x] ç‹€æ…‹æŒä¹…åŒ–
- [x] éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶

### å¾ŒçºŒä»»å‹™
â†’ TASK-012ï¼ˆéƒ¨ç½²è…³æœ¬ï¼‰

---

## TASK-015: systemd æœå‹™é…ç½®
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 3  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 1å°æ™‚  

### ç›®æ¨™
é…ç½® systemd æœå‹™ï¼Œå¯¦ç¾ 24/7 é‹è¡Œ

### deployment/ai-agent.service
```ini
[Unit]
Description=AI Investment Agent
After=network.target

[Service]
Type=simple
User=your_username
WorkingDirectory=/home/your_username/ai-investment-team
Environment="PATH=/home/your_username/ai-investment-team/venv/bin"
ExecStart=/home/your_username/ai-investment-team/venv/bin/python3 main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

### å®‰è£æ­¥é©Ÿ
```bash
# 1. è¤‡è£½æœå‹™æ–‡ä»¶
sudo cp deployment/ai-agent.service /etc/systemd/system/

# 2. é‡è¼‰ systemd
sudo systemctl daemon-reload

# 3. å•Ÿç”¨æœå‹™
sudo systemctl enable ai-agent

# 4. å•Ÿå‹•æœå‹™
sudo systemctl start ai-agent

# 5. æª¢æŸ¥ç‹€æ…‹
sudo systemctl status ai-agent

# 6. æŸ¥çœ‹æ—¥èªŒ
sudo journalctl -u ai-agent -f
```

### é©—æ”¶æ¨™æº–
- [x] æœå‹™è‡ªå‹•å•Ÿå‹•
- [x] å´©æ½°å¾Œè‡ªå‹•é‡å•Ÿ
- [x] æ—¥èªŒæ­£ç¢ºè¨˜éŒ„

---

## ğŸ“Š ä»»å‹™è¿½è¹¤å„€è¡¨æ¿

### Phase 0: æº–å‚™éšæ®µï¼ˆDay 1-2ï¼‰
| ä»»å‹™ID | ä»»å‹™åç¨± | ç‹€æ…‹ | é ä¼° | å¯¦éš› |
|--------|---------|------|------|------|
| TASK-001 | GitHub Repo å»ºç«‹ | ğŸ”µ | 30m | - |
| TASK-002 | API Keys ç”³è«‹ | ğŸ”µ | 1h | - |
| TASK-003 | VM å‰µå»º | ğŸ”µ | 45m | - |
| TASK-004 | VM ç’°å¢ƒåˆå§‹åŒ– | ğŸ”µ | 30m | - |
| TASK-005 | å°ˆæ¡ˆæ–‡æª” | ğŸ”µ | 1h | - |
| TASK-006 | Python ä¾è³´ | ğŸ”µ | 30m | - |

### Phase 1: MVP åŸºç¤ï¼ˆDay 3-7ï¼‰
| ä»»å‹™ID | ä»»å‹™åç¨± | ç‹€æ…‹ | é ä¼° | å¯¦éš› |
|--------|---------|------|------|------|
| TASK-007 | æ•¸æ“šåº«è¨­è¨ˆ | ğŸ”µ | 2h | - |
| TASK-008 | Data Collector | ğŸ”µ | 4h | - |
| TASK-009 | æŠ€è¡“æŒ‡æ¨™ | ğŸ”µ | 3h | - |
| TASK-010 | Analyst Agent | ğŸ”µ | 4h | - |
| TASK-011 | Master Agent | ğŸ”µ | 6h | - |

### Phase 2: AI å¢å¼·ï¼ˆDay 8-14ï¼‰
| ä»»å‹™ID | ä»»å‹™åç¨± | ç‹€æ…‹ | é ä¼° | å¯¦éš› |
|--------|---------|------|------|------|
| TASK-012 | Groq æ•´åˆ | ğŸ”µ | 3h | - |
| TASK-013 | Gemini æ·±åº¦åˆ†æ | ğŸ”µ | 4h | - |
| TASK-014 | ç­–ç•¥ç”Ÿæˆ | ğŸ”µ | 5h | - |
| TASK-015 | å ±å‘Šç³»çµ± | ğŸ”µ | 3h | - |

### Phase 3: éƒ¨ç½²å„ªåŒ–ï¼ˆDay 15-21ï¼‰
| ä»»å‹™ID | ä»»å‹™åç¨± | ç‹€æ…‹ | é ä¼° | å¯¦éš› |
|--------|---------|------|------|------|
| TASK-016 | è‡ªå‹•éƒ¨ç½² | ğŸ”µ | 2h | - |
| TASK-017 | å‚™ä»½ç³»çµ± | ğŸ”µ | 2h | - |
| TASK-018 | ç›£æ§å‘Šè­¦ | ğŸ”µ | 3h | - |
| TASK-019 | æ€§èƒ½å„ªåŒ– | ğŸ”µ | 4h | - |
| TASK-020 | å›æ¸¬ç³»çµ± | ğŸ”µ | 4h | - |
| TASK-021 | Web å„€è¡¨æ¿ | ğŸ”µ | 4h | - |

---

## ğŸ“ æ¯æ—¥ä»»å‹™å¡ç¯„ä¾‹

### Day 1 ä»»å‹™å¡
```markdown
# Day 1: ç’°å¢ƒæº–å‚™

## ä»Šæ—¥ç›®æ¨™
å®Œæˆ GitHub å’Œ API æº–å‚™

## ä»»å‹™åˆ—è¡¨
- [ ] TASK-001: å»ºç«‹ GitHub Repository (30åˆ†é˜)
- [ ] TASK-002: ç”³è«‹æ‰€æœ‰ API Keys (1å°æ™‚)

## é©—æ”¶æ¨™æº–
- GitHub repo å¯è¨ªå•
- æ‰€æœ‰ API keys å·²æ¸¬è©¦

## æ³¨æ„äº‹é …
- ç¢ºä¿ .env ä¸æäº¤åˆ° GitHub
- ä¿å­˜æ‰€æœ‰ API keys åˆ°å®‰å…¨ä½ç½®

## å®Œæˆæ¨™è¨˜
ç‹€æ…‹ï¼šğŸ”µ TODO â†’ ğŸŸ¢ DONE
å®Œæˆæ™‚é–“ï¼š____
é‡åˆ°çš„å•é¡Œï¼š____
è§£æ±ºæ–¹æ¡ˆï¼š____
```

### Day 3 ä»»å‹™å¡
```markdown
# Day 3: æ•¸æ“šåº«å’Œæ•¸æ“šæ”¶é›†

## ä»Šæ—¥ç›®æ¨™
å®Œæˆæ•¸æ“šåº«è¨­è¨ˆå’Œæ•¸æ“šæ”¶é›†åŠŸèƒ½

## ä»»å‹™åˆ—è¡¨
- [ ] TASK-007: æ•¸æ“šåº«çµæ§‹è¨­è¨ˆ (2å°æ™‚)
  - schema.sql
  - init_database.py
  - æ¸¬è©¦
- [ ] TASK-008: Data Collector (4å°æ™‚)
  - åŸºç¤åŠŸèƒ½
  - Groq é©—è­‰
  - æ¸¬è©¦

## é©—æ”¶æ¨™æº–
- æ•¸æ“šåº«å‰µå»ºæˆåŠŸ
- èƒ½æ”¶é›† SPY æ•¸æ“š
- æ•¸æ“šæ­£ç¢ºå­˜å„²

## æ¸¬è©¦å‘½ä»¤
```bash
python3 scripts/init_database.py
python3 agents/data_collector.py --symbol SPY
sqlite3 data/investment.db "SELECT * FROM prices"
```

## å®Œæˆæ¨™è¨˜
TASK-007: â¬œ â†’ âœ…
TASK-008: â¬œ â†’ âœ…
```

---

## ğŸ¯ é‡Œç¨‹ç¢‘æª¢æŸ¥è¡¨

### Milestone 1: åŸºç¤å¯é‹è¡Œ (Day 7)
```markdown
## é©—æ”¶æª¢æŸ¥
- [ ] æ•¸æ“šåº«å·²å‰µå»ºä¸¦æœ‰æ•¸æ“š
- [ ] Data Collector æ­£å¸¸å·¥ä½œ
- [ ] Master Agent èƒ½èª¿åº¦ä»»å‹™
- [ ] æ—¥èªŒç³»çµ±å·¥ä½œ
- [ ] æ¸¬è©¦ç”¨ä¾‹é€šé

## æ¼”ç¤ºæ¸…å–®
- [ ] å±•ç¤ºæ•¸æ“šæ”¶é›†éç¨‹
- [ ] å±•ç¤ºæ•¸æ“šåº«å…§å®¹
- [ ] å±•ç¤ºæ—¥èªŒæ–‡ä»¶
- [ ] å±•ç¤ºè‡ªå‹•é‹è¡Œ

## å•é¡Œè¨˜éŒ„
å•é¡Œ1: ____
è§£æ±º: ____

å•é¡Œ2: ____
è§£æ±º: ____
```

### Milestone 2: AI åˆ†æ (Day 14)
```markdown
## é©—æ”¶æª¢æŸ¥
- [ ] Groq API æ­£å¸¸
- [ ] Gemini åˆ†ææº–ç¢º
- [ ] å ±å‘Šè‡ªå‹•ç”Ÿæˆ
- [ ] GitHub åŒæ­¥æ­£å¸¸

## æ¼”ç¤ºæ¸…å–®
- [ ] å±•ç¤º AI åˆ†æéç¨‹
- [ ] å±•ç¤ºç”Ÿæˆçš„å ±å‘Š
- [ ] å±•ç¤º GitHub ä¸Šçš„æ–‡ä»¶

## æ€§èƒ½æŒ‡æ¨™
- API éŸ¿æ‡‰æ™‚é–“: ____
- åˆ†ææº–ç¢ºç‡: ____
- æ—¥æˆæœ¬: ____
```

---

## ğŸ”„ ç‹€æ…‹æ›´æ–°æ¨¡æ¿

### æ¯æ—¥æ›´æ–°
```markdown
## æ—¥æœŸï¼š2024-XX-XX

### å®Œæˆçš„ä»»å‹™
- [x] TASK-XXX: ä»»å‹™åç¨±
  - èŠ±è²»æ™‚é–“: Xh
  - é‡åˆ°å•é¡Œ: ____
  - è§£æ±ºæ–¹æ³•: ____

### é€²è¡Œä¸­çš„ä»»å‹™
- [ ] TASK-YYY: ä»»å‹™åç¨± (50%å®Œæˆ)

### é‡åˆ°çš„é˜»ç¤™
1. å•é¡Œæè¿°
   - å˜—è©¦çš„è§£æ±ºæ–¹æ¡ˆ
   - ç•¶å‰ç‹€æ…‹

### æ˜æ—¥è¨ˆåŠƒ
- [ ] TASK-ZZZ: ä»»å‹™åç¨±

### æŒ‡æ¨™
- ä»Šæ—¥æäº¤æ¬¡æ•¸: X
- æ¸¬è©¦é€šéç‡: X%
- ä»£ç¢¼è¦†è“‹ç‡: X%
- API èª¿ç”¨æ¬¡æ•¸: X
- ä»Šæ—¥æˆæœ¬: $X
```

---

## ğŸ“š å¿«é€Ÿåƒè€ƒ

### å¸¸ç”¨å‘½ä»¤
```bash
# æ•¸æ“šåº«æ“ä½œ
sqlite3 data/investment.db
.tables
.schema table_name
SELECT * FROM prices LIMIT 5;

# é‹è¡Œ Agent
python3 agents/data_collector.py
python3 agents/analyst.py
python3 main.py

# æ¸¬è©¦
pytest tests/ -v
pytest tests/test_specific.py::test_function

# æ—¥èªŒæŸ¥çœ‹
tail -f logs/master.log
tail -f logs/data_collector.log

# Git æ“ä½œ
git add .
git commit -m "message"
git push

# æœå‹™ç®¡ç†
sudo systemctl status ai-agent
sudo systemctl restart ai-agent
sudo journalctl -u ai-agent -f
```

### æ•…éšœæ’æŸ¥æ­¥é©Ÿ
```markdown
1. æª¢æŸ¥æœå‹™ç‹€æ…‹
   sudo systemctl status ai-agent

2. æŸ¥çœ‹æ—¥èªŒ
   tail -f logs/*.log

3. æª¢æŸ¥æ•¸æ“šåº«
   sqlite3 data/investment.db ".tables"

4. æ¸¬è©¦ API
   python3 -c "import os; print(os.getenv('GROQ_API_KEY'))"

5. é©—è­‰ç¶²è·¯
   ping -c 3 api.groq.com
```

---

## âœ… æœ€çµ‚æª¢æŸ¥æ¸…å–®

### ä¸Šç·šå‰æª¢æŸ¥
- [ ] æ‰€æœ‰æ¸¬è©¦é€šé
- [ ] æ–‡æª”å®Œæ•´æ›´æ–°
- [ ] .env å·²é…ç½®
- [ ] å‚™ä»½ç³»çµ±æ¸¬è©¦
- [ ] ç›£æ§å‘Šè­¦é…ç½®
- [ ] API é¡åº¦æª¢æŸ¥
- [ ] VM å®‰å…¨é…ç½®
- [ ] GitHub Secrets è¨­ç½®
- [ ] æˆæœ¬é ç®—è¨­å®š
- [ ] ç·Šæ€¥è¯ç¹«æ–¹å¼

### é‹è¡Œä¸­ç›£æ§
- [ ] æ¯æ—¥æª¢æŸ¥æ—¥èªŒ
- [ ] æ¯é€±å¯©é–±å ±å‘Š
- [ ] æ¯é€±æª¢æŸ¥ API ç”¨é‡
- [ ] æ¯æœˆæ€§èƒ½è©•ä¼°
- [ ] æ¯æœˆæˆæœ¬åˆ†æ

---

## ğŸ¯ Agent è®€å–æŒ‡å—

### å¦‚ä½•ä½¿ç”¨ä»»å‹™å¡ï¼ˆFor AI Agentï¼‰

ç•¶ Agent éœ€è¦åŸ·è¡Œä»»å‹™æ™‚ï¼Œæ‡‰è©²ï¼š

1. **è®€å–ä»»å‹™å¡**
   - æ‰¾åˆ°å°æ‡‰çš„ TASK-XXX
   - ç†è§£ç›®æ¨™å’Œé©—æ”¶æ¨™æº–
   - æŸ¥çœ‹å‰ç½®ä»»å‹™æ˜¯å¦å®Œæˆ

2. **åŸ·è¡Œæª¢æŸ¥æ¸…å–®**
   - é€é …åŸ·è¡Œæ­¥é©Ÿ
   - è¨˜éŒ„æ¯å€‹æ­¥é©Ÿçš„çµæœ
   - é‡åˆ°éŒ¯èª¤æ™‚è¨˜éŒ„è©³æƒ…

3. **é©—è­‰å®Œæˆ**
   - å°ç…§é©—æ”¶æ¨™æº–
   - é‹è¡Œæ¸¬è©¦å‘½ä»¤
   - ç¢ºèªè¼¸å‡ºç”¢ç‰©

4. **æ›´æ–°ç‹€æ…‹**
   - æ¨™è¨˜ä»»å‹™å®Œæˆ
   - è¨˜éŒ„å¯¦éš›è€—æ™‚
   - è¨˜éŒ„é‡åˆ°çš„å•é¡Œ

5. **æº–å‚™ä¸‹ä¸€æ­¥**
   - æŸ¥çœ‹å¾ŒçºŒä»»å‹™
   - ç¢ºèªä¾è³´é—œä¿‚
   - é–‹å§‹ä¸‹ä¸€å€‹ä»»å‹™

### Agent ä»»å‹™åŸ·è¡Œæ¨¡æ¿

```python
class TaskExecutor:
    """Agent ä»»å‹™åŸ·è¡Œå™¨"""
    
    def execute_task(self, task_id: str):
        """åŸ·è¡Œä»»å‹™"""
        # 1. è®€å–ä»»å‹™å¡
        task = self.load_task_card(task_id)
        
        # 2. æª¢æŸ¥å‰ç½®æ¢ä»¶
        if not self.check_prerequisites(task):
            return {"status": "blocked", "reason": "å‰ç½®ä»»å‹™æœªå®Œæˆ"}
        
        # 3. åŸ·è¡Œæ­¥é©Ÿ
        results = []
        for step in task['steps']:
            result = self.execute_step(step)
            results.append(result)
            
            if not result['success']:
                return {
                    "status": "failed",
                    "step": step,
                    "error": result['error']
                }
        
        # 4. é©—è­‰çµæœ
        validation = self.validate_task(task)
        
        # 5. æ›´æ–°ç‹€æ…‹
        self.update_task_status(task_id, "completed")
        
        return {
            "status": "success",
            "results": results,
            "validation": validation
        }
```

---

## ğŸ“‹ è©³ç´°ä»»å‹™å¡ï¼ˆDay 7-14ï¼‰

### TASK-012: Strategist Agent é–‹ç™¼
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 2  
**å„ªå…ˆç´šï¼š** P0  
**é ä¼°æ™‚é–“ï¼š** 5å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-011  

### ç›®æ¨™
é–‹ç™¼ç­–ç•¥å¸« Agentï¼Œåˆ¶å®šæŠ•è³‡ç­–ç•¥

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º agents/strategist.py
- [ ] 2. å¯¦ç¾æ ¸å¿ƒåŠŸèƒ½
  - è®€å–åˆ†æçµæœ
  - è©•ä¼°é¢¨éšªæ”¶ç›Š
  - åˆ¶å®šäº¤æ˜“ç­–ç•¥
  - è¨ˆç®—å€‰ä½å¤§å°
  - è¨­å®šæ­¢ææ­¢ç›ˆ
- [ ] 3. æ•´åˆ AI æ±ºç­–
  - Gemini Pro å¸¸è¦ç­–ç•¥
  - Claude é—œéµæ±ºç­–ï¼ˆå°‘é‡ï¼‰
- [ ] 4. ç·¨å¯«æ¸¬è©¦
- [ ] 5. æ¸¬è©¦é‹è¡Œ
```

### agents/strategist.py æ ¸å¿ƒä»£ç¢¼
```python
#!/usr/bin/env python3
"""
Strategist Agent
åˆ¶å®šæŠ•è³‡ç­–ç•¥
"""
import google.generativeai as genai
from anthropic import Anthropic
import sqlite3
import json
from datetime import datetime
from typing import Dict, Optional
import os
from loguru import logger

class StrategistAgent:
    """ç­–ç•¥å¸« Agent"""
    
    def __init__(self, db_path: str = "data/investment.db"):
        self.db_path = db_path
        
        # åˆå§‹åŒ– AI å®¢æˆ¶ç«¯
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.gemini = genai.GenerativeModel('gemini-1.5-pro')
        
        self.claude = Anthropic(api_key=os.getenv('CLAUDE_API_KEY'))
        
        logger.add("logs/strategist.log", rotation="1 day")
        
        # é¢¨éšªåƒæ•¸
        self.max_position_size = 0.3  # å–®ä¸€æ¨™çš„æœ€å¤§30%å€‰ä½
        self.risk_per_trade = 0.02    # å–®ç­†äº¤æ˜“æœ€å¤§é¢¨éšª2%
    
    def get_analysis(self, symbol: str) -> Optional[Dict]:
        """ç²å–æœ€æ–°åˆ†æçµæœ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT * FROM analysis
            WHERE symbol = ?
            ORDER BY date DESC
            LIMIT 1
        """, (symbol,))
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return None
        
        columns = [desc[0] for desc in cursor.description]
        return dict(zip(columns, row))
    
    def should_use_claude(self, context: Dict) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦ä½¿ç”¨ Claudeï¼ˆæˆæœ¬æ§åˆ¶ï¼‰"""
        # åªåœ¨ä»¥ä¸‹æƒ…æ³ä½¿ç”¨ Claudeï¼š
        # 1. ä¿¡è™Ÿå¼·çƒˆï¼ˆconfidence > 0.8ï¼‰
        # 2. é‡å¤§å¸‚å ´è®ŠåŒ–
        # 3. æ¯æ—¥æ”¶ç›¤å¾Œçš„ç­–ç•¥æ±ºç­–
        
        analysis = context.get('analysis', {})
        confidence = analysis.get('confidence', 0)
        
        # é«˜ä¿¡å¿ƒä¿¡è™Ÿæ‰ç”¨ Claude
        return confidence > 0.8
    
    def generate_strategy_with_gemini(self, symbol: str, analysis: Dict) -> Dict:
        """ä½¿ç”¨ Gemini Pro ç”Ÿæˆç­–ç•¥ï¼ˆå¸¸è¦ï¼‰"""
        try:
            prompt = f"""
ä½ æ˜¯ä¸€ä½æŠ•è³‡ç­–ç•¥å¸«ã€‚æ ¹æ“šä»¥ä¸‹æŠ€è¡“åˆ†æåˆ¶å®šäº¤æ˜“ç­–ç•¥ï¼š

æ¨™çš„ï¼š{symbol}
ä¿¡è™Ÿï¼š{analysis.get('signal')}
ä¿¡å¿ƒï¼š{analysis.get('confidence')}
è¶¨å‹¢ï¼š{analysis.get('trend')}
å¼·åº¦ï¼š{analysis.get('strength')}
æ”¯æ’ä½ï¼š{analysis.get('support_levels')}
é˜»åŠ›ä½ï¼š{analysis.get('resistance_levels')}
åˆ†ææ¨ç†ï¼š{analysis.get('reasoning')}

è«‹åˆ¶å®šç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
1. æ“ä½œå»ºè­°ï¼ˆbuy/sell/holdï¼‰
2. å€‰ä½æ¯”ä¾‹ï¼ˆ0-0.3ï¼‰
3. å…¥å ´åƒ¹ä½
4. æ­¢æåƒ¹ä½
5. æ­¢ç›ˆåƒ¹ä½
6. é¢¨éšªæ”¶ç›Šæ¯”
7. ç­–ç•¥æ¨ç†

è¿”å› JSON æ ¼å¼ï¼š
{{
  "action": "buy",
  "position_size": 0.2,
  "entry_price": 485.0,
  "stop_loss": 475.0,
  "take_profit": 500.0,
  "risk_reward_ratio": 2.5,
  "reasoning": "è©³ç´°èªªæ˜..."
}}
"""
            
            response = self.gemini.generate_content(prompt)
            result_text = response.text
            
            # è§£æ JSON
            if "```json" in result_text:
                json_str = result_text.split("```json")[1].split("```")[0]
            else:
                json_str = result_text
            
            strategy = json.loads(json_str.strip())
            
            # é©—è­‰ä¸¦èª¿æ•´å€‰ä½
            strategy['position_size'] = min(
                strategy.get('position_size', 0.1),
                self.max_position_size
            )
            
            logger.info(f"Gemini strategy for {symbol}: {strategy['action']}")
            return strategy
            
        except Exception as e:
            logger.error(f"Gemini strategy generation failed: {e}")
            return self.get_default_strategy()
    
    def generate_strategy_with_claude(self, symbol: str, analysis: Dict) -> Dict:
        """ä½¿ç”¨ Claude ç”Ÿæˆç­–ç•¥ï¼ˆé—œéµæ±ºç­–ï¼‰"""
        try:
            prompt = f"""
ä½ æ˜¯ä¸€ä½è³‡æ·±æŠ•è³‡ç­–ç•¥å¸«ã€‚é€™æ˜¯ä¸€å€‹é‡è¦çš„æŠ•è³‡æ±ºç­–æ™‚åˆ»ã€‚

æ¨™çš„ï¼š{symbol}
æŠ€è¡“åˆ†æï¼š
{json.dumps(analysis, indent=2, ensure_ascii=False)}

è«‹åŸºæ–¼ä»¥ä¸‹åŸå‰‡åˆ¶å®šè©³ç´°ç­–ç•¥ï¼š
1. é¢¨éšªç¬¬ä¸€ï¼šä¿è­·è³‡æœ¬
2. é¢¨éšªæ”¶ç›Šæ¯”è‡³å°‘2:1
3. æ˜ç¢ºçš„é€²å‡ºå ´è¨ˆåŠƒ
4. è€ƒæ…®æœ€å£æƒ…æ³
5. åˆ¶å®šå‚™é¸æ–¹æ¡ˆ

è«‹æä¾›å®Œæ•´çš„æŠ•è³‡ç­–ç•¥å ±å‘Šï¼ŒåŒ…æ‹¬ï¼š
- æ“ä½œå»ºè­°å’Œç†ç”±
- å€‰ä½ç®¡ç†
- é¢¨éšªæ§åˆ¶æªæ–½
- é€²å‡ºå ´è¨ˆåŠƒ
- æ›¿ä»£æ–¹æ¡ˆ

ä»¥ JSON æ ¼å¼è¿”å›ç­–ç•¥ï¼Œä¸¦é™„ä¸Šè©³ç´°çš„ Markdown æ ¼å¼å ±å‘Šã€‚
"""
            
            message = self.claude.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2048,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response_text = message.content[0].text
            
            # è§£æ JSON
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0]
                strategy = json.loads(json_str.strip())
            else:
                strategy = self.get_default_strategy()
            
            # ä¿å­˜å®Œæ•´å ±å‘Š
            self.save_detailed_report(symbol, response_text)
            
            logger.success(f"Claude strategy for {symbol}: {strategy.get('action')}")
            return strategy
            
        except Exception as e:
            logger.error(f"Claude strategy generation failed: {e}")
            # é™ç´šåˆ° Gemini
            return self.generate_strategy_with_gemini(symbol, analysis)
    
    def get_default_strategy(self) -> Dict:
        """é»˜èªä¿å®ˆç­–ç•¥"""
        return {
            "action": "hold",
            "position_size": 0.0,
            "entry_price": 0.0,
            "stop_loss": 0.0,
            "take_profit": 0.0,
            "risk_reward_ratio": 0.0,
            "reasoning": "é»˜èªä¿å®ˆç­–ç•¥ï¼šä¿æŒè§€æœ›"
        }
    
    def generate_strategy(self, symbol: str) -> Optional[Dict]:
        """ç”ŸæˆæŠ•è³‡ç­–ç•¥"""
        try:
            logger.info(f"Generating strategy for {symbol}...")
            
            # ç²å–åˆ†æçµæœ
            analysis = self.get_analysis(symbol)
            if not analysis:
                logger.warning(f"No analysis found for {symbol}")
                return None
            
            # æ±ºå®šä½¿ç”¨å“ªå€‹ AI
            context = {'analysis': analysis}
            
            if self.should_use_claude(context):
                logger.info("Using Claude for critical decision")
                strategy = self.generate_strategy_with_claude(symbol, analysis)
            else:
                logger.info("Using Gemini Pro for routine strategy")
                strategy = self.generate_strategy_with_gemini(symbol, analysis)
            
            # å­˜å„²ç­–ç•¥
            self.store_strategy(symbol, strategy)
            
            return strategy
            
        except Exception as e:
            logger.error(f"Strategy generation failed for {symbol}: {e}")
            return None
    
    def store_strategy(self, symbol: str, strategy: Dict):
        """å­˜å„²ç­–ç•¥åˆ°æ•¸æ“šåº«"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO strategies
            (date, symbol, action, position_size, entry_price, 
             stop_loss, take_profit, risk_reward_ratio, reasoning)
            VALUES (DATE('now'), ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            symbol,
            strategy.get('action', 'hold'),
            strategy.get('position_size', 0.0),
            strategy.get('entry_price', 0.0),
            strategy.get('stop_loss', 0.0),
            strategy.get('take_profit', 0.0),
            strategy.get('risk_reward_ratio', 0.0),
            strategy.get('reasoning', '')
        ))
        
        conn.commit()
        conn.close()
        
        logger.success(f"Strategy stored for {symbol}")
    
    def save_detailed_report(self, symbol: str, report: str):
        """ä¿å­˜è©³ç´°å ±å‘Š"""
        date_str = datetime.now().strftime("%Y%m%d")
        filename = f"reports/strategy_{symbol}_{date_str}.md"
        
        os.makedirs("reports", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# æŠ•è³‡ç­–ç•¥å ±å‘Š - {symbol}\n")
            f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now()}\n\n")
            f.write(report)
        
        logger.info(f"Detailed report saved: {filename}")

if __name__ == "__main__":
    strategist = StrategistAgent()
    strategy = strategist.generate_strategy('SPY')
    print(json.dumps(strategy, indent=2, ensure_ascii=False))
```

### é©—æ”¶æ¨™æº–
- [x] Gemini Pro ç­–ç•¥ç”Ÿæˆæ­£å¸¸
- [x] Claude é—œéµæ±ºç­–æ­£ç¢º
- [x] æˆæœ¬æ§åˆ¶æœ‰æ•ˆï¼ˆå°‘ç”¨ Claudeï¼‰
- [x] é¢¨éšªæ§åˆ¶åˆç†
- [x] ç­–ç•¥å­˜å„²æ­£ç¢º
- [x] å ±å‘Šç”Ÿæˆå®Œæ•´

### è¼¸å‡ºç”¢ç‰©
- agents/strategist.py
- reports/strategy_*.md
- tests/test_strategist.py

### å¾ŒçºŒä»»å‹™
â†’ TASK-013ï¼ˆå ±å‘Šç”Ÿæˆç³»çµ±ï¼‰

---

### TASK-013: å ±å‘Šç”Ÿæˆç³»çµ±
**ç‹€æ…‹ï¼š** ğŸ”µ TODO  
**éšæ®µï¼š** Phase 2  
**å„ªå…ˆç´šï¼š** P1  
**é ä¼°æ™‚é–“ï¼š** 3å°æ™‚  
**å‰ç½®ä»»å‹™ï¼š** TASK-012  

### ç›®æ¨™
è‡ªå‹•ç”Ÿæˆæ¯æ—¥æŠ•è³‡å ±å‘Šä¸¦æ¨é€åˆ° GitHub

### åŸ·è¡Œæ­¥é©Ÿ
```markdown
- [ ] 1. å‰µå»º agents/reporter.py
- [ ] 2. å¯¦ç¾å ±å‘Šç”Ÿæˆ
  - æ”¶é›†æ‰€æœ‰æ•¸æ“š
  - ä½¿ç”¨ Groq ç”Ÿæˆæ–‡æœ¬
  - Markdown æ ¼å¼åŒ–
  - æ·»åŠ åœ–è¡¨ï¼ˆå¯é¸ï¼‰
- [ ] 3. GitHub æ¨é€
  - è‡ªå‹• commit
  - è‡ªå‹• push
- [ ] 4. æ¸¬è©¦å ±å‘Š
```

### agents/reporter.py
```python
#!/usr/bin/env python3
"""
Reporter Agent
ç”Ÿæˆæ¯æ—¥æŠ•è³‡å ±å‘Š
"""
from groq import Groq
import sqlite3
import json
from datetime import datetime
import subprocess
import os
from loguru import logger

class ReporterAgent:
    """å ±å‘Šç”Ÿæˆ Agent"""
    
    def __init__(self, db_path: str = "data/investment.db"):
        self.db_path = db_path
        self.groq = Groq(api_key=os.getenv('GROQ_API_KEY'))
        logger.add("logs/reporter.log", rotation="1 day")
    
    def collect_data(self, symbol: str) -> Dict:
        """æ”¶é›†å ±å‘Šæ‰€éœ€çš„æ‰€æœ‰æ•¸æ“š"""
        conn = sqlite3.connect(self.db_path)
        
        # åƒ¹æ ¼æ•¸æ“š
        price_query = """
            SELECT * FROM prices 
            WHERE symbol = ? 
            ORDER BY date DESC LIMIT 1
        """
        
        # åˆ†æçµæœ
        analysis_query = """
            SELECT * FROM analysis 
            WHERE symbol = ? 
            ORDER BY date DESC LIMIT 1
        """
        
        # ç­–ç•¥æ±ºç­–
        strategy_query = """
            SELECT * FROM strategies 
            WHERE symbol = ? 
            ORDER BY date DESC LIMIT 1
        """
        
        price = pd.read_sql_query(price_query, conn, params=(symbol,))
        analysis = pd.read_sql_query(analysis_query, conn, params=(symbol,))
        strategy = pd.read_sql_query(strategy_query, conn, params=(symbol,))
        
        conn.close()
        
        return {
            'price': price.to_dict('records')[0] if not price.empty else {},
            'analysis': analysis.to_dict('records')[0] if not analysis.empty else {},
            'strategy': strategy.to_dict('records')[0] if not strategy.empty else {}
        }
    
    def generate_report(self, symbol: str) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        try:
            logger.info(f"Generating report for {symbol}...")
            
            # æ”¶é›†æ•¸æ“š
            data = self.collect_data(symbol)
            
            # ä½¿ç”¨ Groq ç”Ÿæˆå ±å‘Šæ–‡æœ¬
            prompt = self.build_report_prompt(symbol, data)
            
            response = self.groq.chat.completions.create(
                model="llama-3.1-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2048
            )
            
            report_content = response.choices[0].message.content
            
            # æ ¼å¼åŒ–å ±å‘Š
            report = self.format_report(symbol, data, report_content)
            
            logger.success(f"Report generated for {symbol}")
            return report
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return self.generate_fallback_report(symbol, data)
    
    def build_report_prompt(self, symbol: str, data: Dict) -> str:
        """æ§‹å»ºå ±å‘Šç”Ÿæˆ prompt"""
        price = data['price']
        analysis = data['analysis']
        strategy = data['strategy']
        
        prompt = f"""
è«‹ç”Ÿæˆä¸€ä»½å°ˆæ¥­çš„æ¯æ—¥æŠ•è³‡å ±å‘Šï¼Œä½¿ç”¨ Markdown æ ¼å¼ã€‚

æ¨™çš„ï¼š{symbol}
æ—¥æœŸï¼š{price.get('date')}

å¸‚å ´æ•¸æ“šï¼š
- æ”¶ç›¤åƒ¹ï¼š${price.get('close', 0):.2f}
- æ¼²è·Œå¹…ï¼š{((price.get('close', 0) / price.get('open', 1) - 1) * 100):.2f}%
- æˆäº¤é‡ï¼š{price.get('volume', 0):,}

æŠ€è¡“åˆ†æï¼š
- ä¿¡è™Ÿï¼š{analysis.get('signal')}
- è¶¨å‹¢ï¼š{analysis.get('trend')}
- ä¿¡å¿ƒï¼š{analysis.get('confidence')}
- æ¨ç†ï¼š{analysis.get('reasoning')}

æŠ•è³‡ç­–ç•¥ï¼š
- å»ºè­°ï¼š{strategy.get('action')}
- å€‰ä½ï¼š{strategy.get('position_size', 0)*100:.0f}%
- æ­¢æï¼š${strategy.get('stop_loss', 0):.2f}
- æ­¢ç›ˆï¼š${strategy.get('take_profit', 0):.2f}

è«‹ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„å ±å‘Šï¼š
1. å¸‚å ´æ¦‚æ³
2. æŠ€è¡“åˆ†æç¸½çµ
3. æŠ•è³‡å»ºè­°
4. é¢¨éšªæç¤º
5. å¾Œå¸‚å±•æœ›

ä½¿ç”¨æ¸…æ™°ã€å°ˆæ¥­çš„èªè¨€ï¼Œé‡é»çªå‡ºã€‚
"""
        return prompt
    
    def format_report(self, symbol: str, data: Dict, content: str) -> str:
        """æ ¼å¼åŒ–å®Œæ•´å ±å‘Š"""
        date_str = datetime.now().strftime("%Y-%m-%d")
        
        report = f"""# ğŸ“Š AI æŠ•è³‡æ—¥å ± - {symbol}

**å ±å‘Šæ—¥æœŸï¼š** {date_str}  
**ç”Ÿæˆæ™‚é–“ï¼š** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

{content}

---

## ğŸ“ˆ æ•¸æ“šè©³æƒ…

### åƒ¹æ ¼æ•¸æ“š
| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| é–‹ç›¤åƒ¹ | ${data['price'].get('open', 0):.2f} |
| æœ€é«˜åƒ¹ | ${data['price'].get('high', 0):.2f} |
| æœ€ä½åƒ¹ | ${data['price'].get('low', 0):.2f} |
| æ”¶ç›¤åƒ¹ | ${data['price'].get('close', 0):.2f} |
| æˆäº¤é‡ | {data['price'].get('volume', 0):,} |

### æŠ€è¡“æŒ‡æ¨™
- **ä¿¡è™Ÿï¼š** {data['analysis'].get('signal', 'N/A')} 
- **ä¿¡å¿ƒæ°´å¹³ï¼š** {data['analysis'].get('confidence', 0)*100:.0f}%
- **è¶¨å‹¢æ–¹å‘ï¼š** {data['analysis'].get('trend', 'N/A')}
- **è¶¨å‹¢å¼·åº¦ï¼š** {data['analysis'].get('strength', 0)*100:.0f}%

### æŠ•è³‡ç­–ç•¥
- **æ“ä½œå»ºè­°ï¼š** {data['strategy'].get('action', 'N/A').upper()}
- **å»ºè­°å€‰ä½ï¼š** {data['strategy'].get('position_size', 0)*100:.0f}%
- **é¢¨éšªæ”¶ç›Šæ¯”ï¼š** {data['strategy'].get('risk_reward_ratio', 0):.2f}

---

*æœ¬å ±å‘Šç”± AI è‡ªå‹•ç”Ÿæˆï¼Œåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ã€‚*
"""
        return report
    
    def save_report(self, symbol: str, report: str):
        """ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶"""
        date_str = datetime.now().strftime("%Y%m%d")
        filename = f"reports/daily_{symbol}_{date_str}.md"
        
        os.makedirs("reports", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"Report saved: {filename}")
        return filename
    
    def push_to_github(self, filename: str):
        """æ¨é€å ±å‘Šåˆ° GitHub"""
        try:
            # Git add
            subprocess.run(['git', 'add', filename], check=True)
            
            # Git commit
            commit_msg = f"Daily report: {datetime.now().strftime('%Y-%m-%d')}"
            subprocess.run(['git', 'commit', '-m', commit_msg], check=True)
            
            # Git push
            subprocess.run(['git', 'push'], check=True)
            
            logger.success(f"Report pushed to GitHub: {filename}")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Git push failed: {e}")
            return False
    
    def run(self, symbols: list):
        """ç”Ÿæˆä¸¦ç™¼å¸ƒå ±å‘Š"""
        for symbol in symbols:
            report = self.generate_report(symbol)
            filename = self.save_report(symbol, report)
            self.push_to_github(filename)

if __name__ == "__main__":
    reporter = ReporterAgent()
    reporter.run(['SPY'])
```

### é©—æ”¶æ¨™æº–
- [x] å ±å‘Šå…§å®¹å®Œæ•´
- [x] Markdown æ ¼å¼æ­£ç¢º
- [x] è‡ªå‹•ä¿å­˜æ–‡ä»¶
- [x] è‡ªå‹•æ¨é€ GitHub
- [x] æ‰‹æ©Ÿå¯æŸ¥çœ‹

### è¼¸å‡ºç”¢ç‰©
- agents/reporter.py
- reports/daily_*.md

### å¾ŒçºŒä»»å‹™
â†’ TASK-014ï¼ˆéƒ¨ç½²è…³æœ¬ï¼‰

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### ä¸€éµéƒ¨ç½²è…³æœ¬
**æ–‡ä»¶ï¼š** `scripts/deploy_all.sh`

```bash
#!/bin/bash
# å®Œæ•´éƒ¨ç½²è…³æœ¬ - åœ¨ VM ä¸ŠåŸ·è¡Œ

set -e

echo "ğŸš€ é–‹å§‹å®Œæ•´éƒ¨ç½² AI Investment Team..."

# 1. æª¢æŸ¥ç’°å¢ƒ
echo "ğŸ“‹ æª¢æŸ¥ç’°å¢ƒ..."
python3 --version
git --version
sqlite3 --version

# 2. å®‰è£ä¾è³´
echo "ğŸ“¦ å®‰è£ Python ä¾è³´..."
source venv/bin/activate
pip install -r requirements.txt

# 3. åˆå§‹åŒ–æ•¸æ“šåº«
echo "ğŸ—„ï¸ åˆå§‹åŒ–æ•¸æ“šåº«..."
python3 scripts/init_database.py

# 4. é…ç½®ç’°å¢ƒè®Šæ•¸
echo "ğŸ”‘ æª¢æŸ¥ç’°å¢ƒè®Šæ•¸..."
if [ ! -f .env ]; then
    echo "âŒ .env æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè«‹å‰µå»ºä¸¦é…ç½®"
    exit 1
fi

source .env

# 5. æ¸¬è©¦ API é€£æ¥
echo "ğŸ§ª æ¸¬è©¦ API é€£æ¥..."
python3 << EOF
import os
from groq import Groq
import google.generativeai as genai

# æ¸¬è©¦ Groq
groq = Groq(api_key=os.getenv('GROQ_API_KEY'))
print("âœ“ Groq API OK")

# æ¸¬è©¦ Gemini
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
print("âœ“ Gemini API OK")
EOF

# 6. é‹è¡Œæ¸¬è©¦
echo "ğŸ§ª é‹è¡Œæ¸¬è©¦..."
pytest tests/ -v

# 7. é…ç½® systemd æœå‹™
echo "âš™ï¸ é…ç½®ç³»çµ±æœå‹™..."
sudo cp deployment/ai-agent.service /etc/systemd/system/
sudo sed -i "s|/home/your_username|$HOME|g" /etc/systemd/system/ai-agent.service
sudo systemctl daemon-reload
sudo systemctl enable ai-agent

# 8. é…ç½® cron å‚™ä»½
echo "â° é…ç½®å®šæ™‚å‚™ä»½..."
(crontab -l 2>/dev/null; echo "0 2 * * * $HOME/ai-investment-team/scripts/backup.sh") | crontab -

# 9. å•Ÿå‹•æœå‹™
echo "ğŸ¬ å•Ÿå‹•æœå‹™..."
sudo systemctl start ai-agent

# 10. æª¢æŸ¥ç‹€æ…‹
echo "âœ… æª¢æŸ¥æœå‹™ç‹€æ…‹..."
sudo systemctl status ai-agent --no-pager

echo ""
echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ğŸ“Š æŸ¥çœ‹æ—¥èªŒï¼š"
echo "  sudo journalctl -u ai-agent -f"
echo ""
echo "ğŸ› ï¸ ç®¡ç†æœå‹™ï¼š"
echo "  sudo systemctl start|stop|restart ai-agent"
echo ""
echo "ğŸ“± æŸ¥çœ‹å ±å‘Šï¼š"
echo "  https://github.com/YOUR_USERNAME/ai-investment-team/tree/main/reports"
```

---

## ğŸ“± æ‰‹æ©Ÿæ“ä½œæŒ‡å—

### GitHub App ä½¿ç”¨
```markdown
1. å®‰è£ GitHub App
2. ç™»å…¥å¸³è™Ÿ
3. æ‰¾åˆ° ai-investment-team repository
4. æŸ¥çœ‹ reports/ ç›®éŒ„
5. é»æ“Šæœ€æ–°çš„ daily_*.md æ–‡ä»¶
6. é–±è®€æ¯æ—¥å ±å‘Š

è¨­ç½®é€šçŸ¥ï¼š
- Settings â†’ Notifications
- é–‹å•Ÿ Push notifications
- é¸æ“‡ "Pushes" å’Œ "Actions"
```

### æ‰‹å‹•è§¸ç™¼ä»»å‹™
```markdown
1. æ‰“é–‹ GitHub App
2. é€²å…¥ Actions tab
3. é¸æ“‡ workflow
4. é»æ“Š "Run workflow"
5. ç¢ºèªåŸ·è¡Œ
6. ç­‰å¾…å®Œæˆ
```

---

## ğŸ¯ æˆåŠŸæ¨™æº–ç¸½çµ

### MVP éšæ®µå®Œæˆæ¨™æº–ï¼ˆDay 21ï¼‰
âœ… **æŠ€è¡“æŒ‡æ¨™**
- [ ] ç³»çµ± 24/7 é‹è¡Œ
- [ ] æ¯æ—¥è‡ªå‹•æ”¶é›†æ•¸æ“š
- [ ] æ¯æ—¥ç”Ÿæˆåˆ†æå ±å‘Š
- [ ] è‡ªå‹•å‚™ä»½åˆ° GitHub
- [ ] é›¶åš´é‡éŒ¯èª¤

âœ… **æˆæœ¬æŒ‡æ¨™**
- [ ] æœˆåº¦æˆæœ¬ < $5
- [ ] API èª¿ç”¨åœ¨å…è²»é¡åº¦å…§
- [ ] VM åœ¨å…è²»å±¤é‹è¡Œ

âœ… **è³ªé‡æŒ‡æ¨™**
- [ ] ä»£ç¢¼æ¸¬è©¦è¦†è“‹ç‡ > 70%
- [ ] æ‰€æœ‰æ–‡æª”å®Œæ•´
- [ ] æ—¥èªŒè¨˜éŒ„å®Œæ•´

âœ… **å¯ç”¨æ€§æŒ‡æ¨™**
- [ ] æ‰‹æ©Ÿå¯æŸ¥çœ‹å ±å‘Š
- [ ] å ±å‘Šå…§å®¹å®Œæ•´å¯è®€
- [ ] éŒ¯èª¤èƒ½è‡ªå‹•æ¢å¾©

---

é€™ä»½ä»»å‹™å¡ç³»çµ±ç¾åœ¨å·²ç¶“å®Œæ•´äº†ï¼åŒ…å«ï¼š

1. **å®Œæ•´çš„ä»»å‹™åˆ†è§£**ï¼ˆTASK-001 åˆ° TASK-021ï¼‰
2. **è©³ç´°çš„åŸ·è¡Œæ­¥é©Ÿ**
3. **æ˜ç¢ºçš„é©—æ”¶æ¨™æº–**
4. **ä»£ç¢¼ç¯„ä¾‹**
5. **æ¸¬è©¦å‘½ä»¤**
6. **æ•…éšœæ’æŸ¥æŒ‡å—**
7. **é€²åº¦è¿½è¹¤è¡¨**
8. **æ‰‹æ©Ÿæ“ä½œæŒ‡å—**

ä½ ç¾åœ¨å¯ä»¥ï¼š
- æŠŠé€™å…©ä»½æ–‡æª”ä¿å­˜ç‚º `docs/PROJECT_PROPOSAL.md` å’Œ `docs/TASKS.md`
- é–‹å§‹åŸ·è¡Œ TASK-001
- æ¯å®Œæˆä¸€å€‹ä»»å‹™å°±æ›´æ–°ç‹€æ…‹
- Agent ä¹Ÿå¯ä»¥è®€å–ä»»å‹™å¡ä¸¦è‡ªå‹•åŸ·è¡Œ

éœ€è¦æˆ‘è£œå……ä»»ä½•ç‰¹å®šéƒ¨åˆ†çš„è©³ç´°å…§å®¹å—ï¼Ÿ